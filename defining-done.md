# Doneness

> This document was produced as part of Accelerating AI in the Arts and Humanities (AAAH) produces outputs of professional quality for the research community. 
> This means making it easier for your current and future research, accelerating the impact and legacy of the software, expanding communities of practice, and providing a confident codebase for future research. 
> This framework highlights what a maximal 'definition of done' would look like for mutual success to deliver reproducible and credible code for all. 
> It is expected that not all engagements will hit the maximum extents, but rather this is to be negotiated and shaped by the resources available.

>For each project within AAAH determine which "Level" in each of the following categories is a minimum aim for defining done:


## Functionality

Level 01. **Standard use**: Install the tool, try out a standard use case, write a demo if one doesn't exist
Level 02. **Known Limitations**: Understand and report. 
Level 03. **Advanced use**: Try out normal range but more advanced use cases, with edge cases. 
Level 04. **New features**: Identifying features for new functionality.
Level 05. **Enhancements**: Fix functionality bugs and add features.



## Documentation

Level 01. **Follow docs**: Follow the existing starting point of documentation (no help!)
Level 02. **What's missing**: Identify what documentation is missing: e.g. installation, optional arguments, licensing, diagrams/screenshots, future work, etc. 
Level 03. **Write docs**: Write the documentation in markdown files
Level 04. **Published**: Release the documentation on GitPages etc
Level 05. **Walkthrough**: Write walkthroughs/demos (also gifs or videos)

## Testing

Level 01. **Fix Tests**: Running and trying tests that already exist, improving them
Level 02. **Pseudo Tests**: Identifying where tests need to be added, writing "pseudo-tests"
Level 03. **Write Tests**: Writing unit tests in the code with clear outputs and show coverage
Level 04. **Automate & Continuous Integration (CI)**:  Creating continuous integration tests with Github Actions
Level 05. **End to End Tests**: Simulates real world use.


## Open Release
> Assuming the tool CAN be open
> Community and contribution

Level 01. **Find barriers**: Identify minimum criteria that need to be solved before public release e.g. authorship, sensitivity, licensing, publicity, timings
Level 02. **Solve barriers**: Address the minimum criteria and milestone efforts
Level 03. **Release**: Make the repo public.
Level 04. **Distribute**: Release the repo on PiPY or CRAN or equivalent, include DOI
Level 05. **Publisise**: Publish the repo with JOSS, and/or publicly present the work. 

## Reach and Robustness

Level 01. **Internal users**: Identify how users already use the tool and its current issues.
Level 02. **Best practices**: Address minimum code best practices with view to robustness and accessibility eg. [`dependabot`](https://github.com/dependabot/dependabot-core)
Level 03. **External users**: Identify how similar external users could use the tool and current barriers
Level 04. **Generalise**: Identify how the tool could be made general and current barriers to that
Level 05. **Proof of concept**: Demonstrate its use outside its original intended purpose/audience. 

